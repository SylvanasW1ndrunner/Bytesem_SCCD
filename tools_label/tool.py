"""
Purpose: Evaluates baseline clone detection tools against the test dataset.
Compares performance of traditional tools like Deckard, EClone, Nicad, etc.
"""

import os
import numpy as np
import pandas as pd
import json
from sklearn.metrics import classification_report, recall_score
from tqdm import tqdm

BASELINE_DATA_DIR = "../../2_tools_label/dataset_II_contract_level/"
TEST_CSV_PATH = "../test.csv"
CONTRACT_MAP_PATH = os.path.join(BASELINE_DATA_DIR, "index_map/contract_label_380.json")
OUTPUT_REPORT_PATH = "baseline_performance_report.txt"

TOOLS = {
    "Deckard": "Deckard/compressed_matrix.npy",
    "EClone": "EClone/compressed_matrix.npy",
    "Nicad": "Nicad/compressed_matrix.npy",
    "SmartEmbed": "SmartEmbed/compressed_matrix.npy",
    "SourcererCC": "SourcererCC/compressed_matrix.npy",
}

# TODO: Explore and analyze .npy file contents for debugging
def explore_npy_file(filepath, max_rows=5):
    if not os.path.exists(filepath):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return

    try:
        print(f"ğŸ“ æ­£åœ¨åŠ è½½æ–‡ä»¶: {filepath}")
        print("=" * 50)

        data = np.load(filepath, allow_pickle=True)

        print("ğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"   æ•°æ®ç±»å‹: {type(data)}")
        print(f"   NumPy æ•°æ®ç±»å‹: {data.dtype}")
        print(f"   æ•°æ®å½¢çŠ¶: {data.shape}")
        print(f"   ç»´åº¦æ•°: {data.ndim}")
        print(f"   æ€»å…ƒç´ æ•°: {data.size}")
        print(f"   å†…å­˜å ç”¨: {data.nbytes / 1024:.2f} KB")
        print()

        if data.ndim == 0:
            print("ğŸ“‹ æ•°æ®å†…å®¹ (æ ‡é‡):")
            print(f"   å€¼: {data}")

        elif data.ndim == 1:
            print("ğŸ“‹ æ•°æ®å†…å®¹ (ä¸€ç»´æ•°ç»„):")
            print(f"   é•¿åº¦: {len(data)}")
            print(f"   å‰ {min(max_rows, len(data))} ä¸ªå…ƒç´ :")
            for i, item in enumerate(data[:max_rows]):
                print(f"   [{i}]: {item}")
            if len(data) > max_rows:
                print(f"   ... (è¿˜æœ‰ {len(data) - max_rows} ä¸ªå…ƒç´ )")

        elif data.ndim == 2:
            print("ğŸ“‹ æ•°æ®å†…å®¹ (äºŒç»´æ•°ç»„/è¡¨æ ¼):")
            print(f"   è¡Œæ•°: {data.shape[0]}")
            print(f"   åˆ—æ•°: {data.shape[1]}")

            print("\n   åˆ—ç´¢å¼•:", end="")
            for j in range(min(10, data.shape[1])):
                print(f"{j:>10}", end="")
            if data.shape[1] > 10:
                print("       ...")
            else:
                print()

            rows_to_show = min(max_rows, data.shape[0])
            print(f"\n   å‰ {rows_to_show} è¡Œæ•°æ®:")
            for i in range(rows_to_show):
                print(f"   [{i}]:", end="")
                cols_to_show = min(10, data.shape[1])
                for j in range(cols_to_show):
                    if np.issubdtype(data.dtype, np.floating):
                        print(f"{data[i, j]:>10.3f}", end="")
                    else:
                        print(f"{data[i, j]:>10}", end="")
                if data.shape[1] > 10:
                    print("       ...")
                else:
                    print()

            if data.shape[0] > max_rows:
                print(f"   ... (è¿˜æœ‰ {data.shape[0] - max_rows} è¡Œ)")

        else:
            print(f"ğŸ“‹ æ•°æ®å†…å®¹ ({data.ndim}ç»´æ•°ç»„):")
            print("   è¿™æ˜¯ä¸€ä¸ªé«˜ç»´æ•°ç»„ï¼Œæ˜¾ç¤ºæ•´ä½“ç»Ÿè®¡ä¿¡æ¯:")

            if np.issubdtype(data.dtype, np.number):
                print(f"   æœ€å°å€¼: {np.min(data)}")
                print(f"   æœ€å¤§å€¼: {np.max(data)}")
                print(f"   å¹³å‡å€¼: {np.mean(data):.3f}")
                print(f"   æ ‡å‡†å·®: {np.std(data):.3f}")

            print(f"\n   ç¬¬ä¸€ä¸ªåˆ‡ç‰‡ [0] çš„å½¢çŠ¶: {data[0].shape}")
            print(f"   ç¬¬ä¸€ä¸ªåˆ‡ç‰‡çš„å‰å‡ ä¸ªå…ƒç´ :")
            flat_slice = data[0].flatten()
            for i, item in enumerate(flat_slice[:10]):
                print(f"   [{i}]: {item}")
            if len(flat_slice) > 10:
                print(f"   ... (è¯¥åˆ‡ç‰‡è¿˜æœ‰ {len(flat_slice) - 10} ä¸ªå…ƒç´ )")

        if data.dtype == 'object':
            print("\nâš ï¸  æ³¨æ„: è¿™æ˜¯ä¸€ä¸ªå¯¹è±¡æ•°ç»„ï¼Œå¯èƒ½åŒ…å«å¤æ‚çš„Pythonå¯¹è±¡")
            print("   ç¬¬ä¸€ä¸ªå…ƒç´ çš„ç±»å‹:", type(data.flat[0]) if data.size > 0 else "ç©ºæ•°ç»„")

        print("\n" + "=" * 50)
        print("âœ… æ–‡ä»¶æ¢ç´¢å®Œæˆ!")

        return data

    except Exception as e:
        print(f"âŒ åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None

# TODO: Evaluate all baseline tools against test dataset
def evaluate_all_baselines():
    print("æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®å’Œæ˜ å°„æ–‡ä»¶...")
    try:
        test_df = pd.read_csv(TEST_CSV_PATH)
        with open(CONTRACT_MAP_PATH, 'r', encoding='utf-8') as f:
            name_to_idx = json.load(f)
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ°å¿…è¦æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥é…ç½®åŒºåŸŸçš„è·¯å¾„ - {e}")
        return

    with open(OUTPUT_REPORT_PATH, "w", encoding="utf-8") as report_file:
        report_file.write("="*30 + " åŸºçº¿å·¥å…·æ€§èƒ½è¯„ä¼°æŠ¥å‘Š " + "="*30 + "\n\n")
        print(f"æŠ¥å‘Šå°†ä¿å­˜è‡³: {OUTPUT_REPORT_PATH}")

        for tool_name, matrix_suffix in TOOLS.items():
            matrix_path = os.path.join(BASELINE_DATA_DIR, matrix_suffix)

            print(f"\n--- æ­£åœ¨è¯„ä¼°å·¥å…·: {tool_name} ---")
            report_file.write(f"--- å·¥å…·: {tool_name} ---\n")

            if not os.path.exists(matrix_path):
                print(f"  - è­¦å‘Š: æ‰¾ä¸åˆ°ç»“æœçŸ©é˜µ {matrix_path}ï¼Œè·³è¿‡è¯¥å·¥å…·ã€‚")
                report_file.write("  - ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è¯„ä¼°ã€‚\n\n")
                continue
            with open(matrix_path,'rb') as f:
                result_matrix = np.unpackbits(np.load(f))[:144400].reshape((380, 380))
                print(f"  - è¯»å–ç»“æœçŸ©é˜µ {matrix_path} æˆåŠŸã€‚")
                print(f"  - çŸ©é˜µå¤§å°ï¼š", result_matrix.ndim)
            y_true = []
            y_pred = []

            for row in tqdm(test_df.to_dict('records'), desc=f"Processing {tool_name}"):
                id1, id2 = row['contract_id'], row['clone_contract_id']
                groundtruth = int(row['groundtruth'])

                idx1 = name_to_idx.get(id1)
                idx2 = name_to_idx.get(id2)

                if idx1 is None or idx2 is None:
                    continue

                predicted_type = result_matrix[idx1, idx2]
                pred_binary = 1 if predicted_type > 0 else 0

                y_true.append(groundtruth)
                y_pred.append(pred_binary)

            if not y_true:
                print("  - é”™è¯¯: æœªèƒ½å¤„ç†ä»»ä½•æœ‰æ•ˆçš„æ•°æ®å¯¹ã€‚è¯·æ£€æŸ¥CSVå’ŒJSONæ–‡ä»¶çš„åˆçº¦åç§°æ˜¯å¦åŒ¹é…ã€‚")
                report_file.write("  - æœªèƒ½å¤„ç†ä»»ä½•æœ‰æ•ˆçš„æ•°æ®å¯¹ã€‚\n\n")
                continue

            report_str = classification_report(y_true, y_pred, target_names=["Not Clone (Type 0)", "Clone (Type 1-4)"], digits=4)
            print("\n  --- æ•´ä½“æ€§èƒ½æŒ‡æ ‡ ---")
            print(report_str)
            report_file.write("\næ•´ä½“æ€§èƒ½æŒ‡æ ‡:\n")
            report_file.write(report_str + "\n")

            test_df['predicted'] = y_pred
            clone_df = test_df[test_df['groundtruth'] == 1]

            print("\n  --- å„ç±»å‹å…‹éš†çš„ç‹¬ç«‹å¬å›ç‡ (Recall) ---")
            report_file.write("\nå„ç±»å‹å…‹éš†çš„ç‹¬ç«‹å¬å›ç‡ (Recall):\n")

            for clone_type in [1.0, 2.0, 3.0, 4.0]:
                type_df = clone_df[clone_df['type'] == clone_type]
                if len(type_df) == 0:
                    recall_str = f"  - Type-{int(clone_type)} Recall: N/A (æµ‹è¯•é›†ä¸­æ— æ­¤ç±»å‹æ ·æœ¬)\n"
                else:
                    recall = recall_score(type_df['groundtruth'], type_df['predicted'], zero_division=0)
                    correctly_found = type_df['predicted'].sum()
                    total = len(type_df)
                    recall_str = f"  - Type-{int(clone_type)} Recall: {recall:.4f} ({correctly_found} / {total})\n"

                print(recall_str.strip())
                report_file.write(recall_str)

            report_file.write("\n" + "="*70 + "\n\n")
            print(f"--- {tool_name} è¯„ä¼°å®Œæˆ ---")

    print("\næ‰€æœ‰åŸºçº¿å·¥å…·è¯„ä¼°å®Œæ¯•ï¼")

if __name__ == '__main__':
    evaluate_all_baselines()